{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стохастический анализ (2024)\n",
    "# Домашнее Задание 4\n",
    "\n",
    "ВАШЕ ИМЯ ЗДЕСЬ\n",
    "\n",
    "Оценка: ?? из 100\n",
    "\n",
    "\n",
    "Задачи: ?? из \n",
    "\n",
    "Ноутбук: ?? из 40\n",
    "\n",
    "\n",
    "Дедлайн: ??, 2359МСК\n",
    "\n",
    "Решённый ноутбук нужно засабмитить в класрум курса\n",
    "\n",
    "Пожалуйста, называйте файл(ы) в формате <Имя>HW4.pdf или <Имя>HW4.ipynb. Например, KaledinHW4.pdf и KaledinHW4.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all imports here, pls\n",
    "import numpy as np\n",
    "import scipy.stats as spstats\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом ноутбуке мы более плотно поисследуем некоторые физические явления в микро- и макромасштабе с помощью численных методов, а также ещё посмотрим на MCMC в действии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Диффузии (30 баллов)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (20 баллов) Алгоритмы семплирования\n",
    "\n",
    "Мы будем исследовать две цепи: от алгоритма ULA и алгоритма MALA. Для реализации этих методов вам прежде всего понадобится метод Эйлера (используйте свою реализацию или дополните реализацию ниже)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDESolver:\n",
    "    \n",
    "    def __init__(self, b, sigma):\n",
    "        self.b = b \n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def step(self, x, t, tnext):\n",
    "        \"\"\"One integration step\n",
    "\n",
    "        Raises:\n",
    "            NotImplementedError: if not implemented\n",
    "        \"\"\"        \n",
    "        raise NotImplementedError\n",
    "    \n",
    "    #added returnLast to not store everything\n",
    "    #added kwargs to send additional arguments to step through solve\n",
    "    def solve(self, x0, ts, returnLast=False, loaderLabel=\"Solving....\", **kwargs):\n",
    "        \"\"\"Computes the solution on the given grid ts with x0 as initial condition\n",
    "\n",
    "        Args:\n",
    "            x0 float[]: initial condition (N,d,) or (d,)\n",
    "            ts float[]: time grid (T,)\n",
    "            tIds float[]: optional, ids in the dense time grid (sent through kwargs, needed for experiments)\n",
    "        Returns:\n",
    "            xs float[]: approximated solution (N,d,T) at points ts\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if(len(x0.shape)==1):\n",
    "                x0 = x0[None, :]\n",
    "        except:\n",
    "            #a number?\n",
    "            x0 = np.ones([1,1])*x0\n",
    "            \n",
    "        \n",
    "        if(returnLast):\n",
    "            xs = x0    \n",
    "        else:            \n",
    "            xs = np.zeros([x0.shape[0], x0.shape[1], len(ts)])\n",
    "            xs[...,0] = x0\n",
    "        \n",
    "        print(loaderLabel)\n",
    "        for i in tqdm.tqdm(np.arange(1,len(ts))):\n",
    "            if(returnLast):\n",
    "                xs = self.step(xs,ts[i-1],ts[i],**kwargs)\n",
    "            else:\n",
    "                xs[...,i] = self.step(xs[...,i-1],ts[i-1],ts[i],**kwargs)\n",
    "        \n",
    "        return xs\n",
    "    \n",
    "class EulerSolver(SDESolver):\n",
    "    \n",
    "    def __init__(self,b,sigma):\n",
    "        super(EulerSolver, self).__init__(b,sigma)\n",
    "        \n",
    "    def step(self, x, t, tnext,**kwargs):\n",
    "        \"\"\"Makes Euler step\n",
    "\n",
    "        Args:\n",
    "            x float[]: previous point (N,d)\n",
    "            t float: previous time\n",
    "            tnext float: next time\n",
    "        \"\"\"            \n",
    "        #b (N,d)  x (N,d)   sigma (N,d,d)\n",
    "        #NEW!! improved to handle sigma as matrix\n",
    "        if(x.ndim==1): #in case we still got (d,)\n",
    "            x = x[None,:]\n",
    "        \n",
    "        #???YOUR CODE\n",
    "       \n",
    "        #res = ???\n",
    "        #return res\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё нам понадобится обёртка для семплера, семплер ULA и семплер MALA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def sample(self, N):\n",
    "        \"\"\"Samles N points\n",
    "\n",
    "        Args:\n",
    "            N (int): number of points to sample\n",
    "\n",
    "        Raises:\n",
    "            NotImplementedError: since needs override\n",
    "        \"\"\"        \n",
    "        raise NotImplementedError\n",
    "\n",
    "#for simplicity, a start sampler\n",
    "class ConstSampler(Sampler):\n",
    "    \n",
    "    def __init__(self, const):\n",
    "        '''\n",
    "        Returns a const vector const (d,)\n",
    "        '''\n",
    "        self.const = const\n",
    "        \n",
    "    def sample(self,N):\n",
    "        return self.const[None,:]*np.ones([N,1])\n",
    "    \n",
    "    \n",
    "class GaussianSampler(Sampler):\n",
    "    \n",
    "    def __init__(self, mu, cov):\n",
    "        self.mu = mu\n",
    "        self.cov = cov\n",
    "    \n",
    "    def sample(self,N):\n",
    "        return np.random.multivariate_normal(self.mu,self.cov, size=(N,))\n",
    "    \n",
    "class UniformSampler(Sampler):\n",
    "    \n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "    \n",
    "    def sample(self,N):\n",
    "        return np.random.uniform(size=(N,self.left.shape[0]))*(self.right - self.left) + (self.right + self.left)/2\n",
    "    \n",
    "    \n",
    "class ULASampler(Sampler):\n",
    "    \n",
    "    def __init__(self, gradLog, startSampler, delta=0.01):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            gradLog functionHandler: function mapping R^d tp R^d, gradient of the logarithm\n",
    "            delta float: discrete time step, defaults to 0.01\n",
    "            startSampler functionHandler: maps int N to a set of N samples\n",
    "        \"\"\"        \n",
    "        super(ULASampler,self).__init__()\n",
    "        self.gradLog = gradLog\n",
    "        self.delta = delta\n",
    "        self.startSampler = startSampler\n",
    "        \n",
    "        #pass t because of solver\n",
    "        def sigg(t,x):\n",
    "            return np.sqrt(2)*np.eye(x.shape[1])[None,...] * np.ones([x.shape[0],x.shape[1],x.shape[1]])\n",
    "        self.solver = EulerSolver(self.gradLog,sigma=sigg)\n",
    "        \n",
    "    def sample(self, N, burnIn=20000, parallelChains=False):\n",
    "        \"\"\"Samles N points\n",
    "\n",
    "        Args:\n",
    "            N (int): number of points to sample\n",
    "            burnIn (int): number of samples to burn before sampling\n",
    "\n",
    "        Raises:\n",
    "            NotImplementedError: since needs override\n",
    "        \"\"\"        \n",
    "        Tburned = burnIn*self.delta\n",
    "        tsBurn = np.arange(0,Tburned+3*self.delta/2,self.delta)#if you need it....\n",
    "        if(parallelChains):\n",
    "            #CASE of parallel sampling: run N chains in parallel, collect the last state\n",
    "            startPoints = self.startSampler.sample(N)\n",
    "            #make burn-in, save the last observation\n",
    "            #result = #???\n",
    "            print(\"Sampling...\")\n",
    "            #actually the last observation is the sample\n",
    "        else:\n",
    "            #CASE of sequential sampling: wait and then collect, one trajectory\n",
    "            startPoints = self.startSampler.sample(1)\n",
    "            #make burn-in, save the last observation\n",
    "            #then collect samples\n",
    "            #burned = ???\n",
    "            result = np.zeros([N,startPoints.shape[-1]])\n",
    "            #result[0,:]=burned\n",
    "            print(\"Sampling...\")\n",
    "            for i in tqdm.tqdm(np.arange(1,N)):\n",
    "                #????\n",
    "            #result (N,d) is the sample of N observations\n",
    "                \n",
    "        #return result\n",
    "        pass\n",
    "    \n",
    "    def _odeStep(self,x):\n",
    "        #one step of the solver\n",
    "        return self.solver.step(x,0,self.delta)\n",
    "         \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим теперь ULASampler на простом примере семплирования из $N(1,1)$. Постройте диффузию Ланжевена для семплирования из этого распределения.\n",
    "\n",
    "ВАШЕ РЕШЕНИЕ ТУТ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass t because of solver\n",
    "def gradLog(t,x):\n",
    "    return -(x-1)\n",
    "\n",
    "startSampler = ConstSampler(np.zeros([1]))\n",
    "delta = 0.001\n",
    "ulaSampler = ULASampler(gradLog,startSampler,delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleParallel = ulaSampler.sample(10000,burnIn=100000, parallelChains=True)\n",
    "sampleSequential = ulaSampler.sample(10000,burnIn=100000, parallelChains=False)\n",
    "print(sampleParallel.shape,sampleSequential.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "ax.grid()\n",
    "ax.set_title(\"Гистограммы семплов\")\n",
    "ax.hist(sampleParallel[:,0], alpha=0.7,density=True,)\n",
    "ax.hist(sampleSequential[:,0], alpha=0.7,density=True)\n",
    "ax.legend([\"Parallel\",\"Sequential\"])\n",
    "\n",
    "xx = np.arange(-3,4,0.01)\n",
    "normPDF = spstats.norm.pdf(xx-1)\n",
    "ax.plot(xx,normPDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У Sequential-версии распределение немного отличается в силу коррелированности семплов, но у обеих версий примерно в одном месте находятся мода и матожидание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь алгоритм MALA. Он несильно отличается от ULA, но нам понадобится дополнительно знание плотности с точностью до константы нормировки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё нужно явно выписать пропоузал, он НЕсимметричный и его надо вычислять. Нужно с точностью до нормировочной константы(она сократится) вычислить\n",
    "\n",
    "$$\n",
    "q(X' \\vert X_t) = ???\n",
    "$$\n",
    "\n",
    "$$\n",
    "q(X_t \\vert X') = ???\n",
    "$$\n",
    "\n",
    "Запишите формулы для плотностей пропоузала в ULA ниже (это важно! потом может быть очень сложно искать ошибку)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАШЕ РЕШЕНИЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MALASampler(ULASampler):\n",
    "    \n",
    "    def __init__(self, gradLog, startSampler, density, delta=0.01):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            gradLog functionHandler: function mapping R^d tp R^d, gradient of the logarithm\n",
    "            delta float: discrete time step, defaults to 0.01\n",
    "            startSampler functionHandler: maps int N to a set of N samples\n",
    "            density functionHandler: maps R^d tp R, density function up to normalization constant\n",
    "        \"\"\"        \n",
    "        super(MALASampler,self).__init__(gradLog, startSampler, delta)\n",
    "        self.density = density\n",
    "        \n",
    "    def sample(self, N, burnIn=20000, parallelChains=False):\n",
    "        \"\"\"Samles N points\n",
    "\n",
    "        Args:\n",
    "            N (int): number of points to sample\n",
    "            burnIn (int): number of samples to burn before sampling\n",
    "\n",
    "        Raises:\n",
    "            NotImplementedError: since needs override\n",
    "        \"\"\"        \n",
    "\n",
    "        if(parallelChains):\n",
    "            #CASE of parallel sampling: run N chains in parallel, collect the last state\n",
    "            startPoints = self.startSampler.sample(N)\n",
    "            print(\"Burning...\")\n",
    "            res = startPoints\n",
    "            for i in tqdm.tqdm(np.arange(burnIn)):\n",
    "                #??? YOUR CODE\n",
    "                pass\n",
    "            print(\"Sampling...\")\n",
    "            result = res\n",
    "        else:\n",
    "            #CASE of sequential sampling: wait and then collect, one trajectory\n",
    "            startPoints = self.startSampler.sample(1)\n",
    "            print(\"Burning...\")\n",
    "            #make burn in with _MHStep, save the last state\n",
    "            #then collect the samples\n",
    "            result = np.zeros([N,startPoints.shape[-1]])\n",
    "            result[0,:]=res\n",
    "            print(\"Sampling...\")\n",
    "            for i in tqdm.tqdm(np.arange(1,N)):\n",
    "                #?? YOUR CODE\n",
    "                pass\n",
    "                \n",
    "        #return result\n",
    "    \n",
    "    def _odeStep(self,x):\n",
    "        return self.solver.step(x,0,self.delta)\n",
    "    \n",
    "    def _MHStep(self, x):\n",
    "        \n",
    "        xNew = # make a proposal with _odeStep(x) #t is bypassed\n",
    "        \n",
    "        #calculate proposal log densities \n",
    "        #x->xNew\n",
    "        #xxNewLogDens = ???\n",
    "        #xNew->x\n",
    "        #xNewxLogDens = ???\n",
    "        \n",
    "        #calculate acceptance probability\n",
    "        #use np.log WHEREVER YOU CAN for numerical stability\n",
    "        accRatios = #????\n",
    "        acceptProbs = #????\n",
    "        accepted = np.random.uniform(size=acceptProbs.shape)<acceptProbs\n",
    "        \n",
    "        #make a decision\n",
    "        return accepted[:,None]*xNew + (1-accepted)[:,None]*x\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass t because of solver\n",
    "def gradLog(t,x):\n",
    "    return -(x-1)\n",
    "def density(x):\n",
    "    return np.exp(-(x-1)**2/2).squeeze()\n",
    "\n",
    "startSampler = ConstSampler(np.zeros([1]))\n",
    "delta = 0.01\n",
    "malaSampler = MALASampler(gradLog,startSampler,density,delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleParallel = malaSampler.sample(10000,burnIn=100000, parallelChains=True)\n",
    "sampleSequential = malaSampler.sample(10000,burnIn=100000, parallelChains=False)\n",
    "print(sampleParallel.shape,sampleSequential.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "ax.grid()\n",
    "ax.set_title(\"Гистограммы семплов(MALA)\")\n",
    "ax.hist(sampleParallel[:,0], alpha=0.7,density=True,)\n",
    "ax.hist(sampleSequential[:,0], alpha=0.7,density=True)\n",
    "ax.legend([\"Parallel\",\"Sequential\"])\n",
    "\n",
    "xx = np.arange(-3,4,0.01)\n",
    "normPDF = spstats.norm.pdf(xx-1)\n",
    "ax.plot(xx,normPDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сходимость не зависит от того, с какого распределения мы стартовали. Давайте попробуем семплировать из такого же распределения, но запустим два варианта цепи (обе в режиме sequential): с началом в  $7$ и с началом в $-4$.\n",
    "\n",
    "Нарисуйте ниже графики, где по оси х отложено время, а по оси y -- значения цепей. Не забуьте про $\\texttt{burnIn}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass t because of solver\n",
    "def gradLog(t,x):\n",
    "    return -(x-1)\n",
    "def density(x):\n",
    "    return np.exp(-(x-1)**2/2).squeeze()\n",
    "\n",
    "startSampler1 = ConstSampler(np.array([7]))\n",
    "startSampler2 = ConstSampler(np.array([-5]))\n",
    "delta = 0.01\n",
    "malaSampler1 = MALASampler(gradLog,startSampler1,density,delta)\n",
    "malaSampler2 = MALASampler(gradLog,startSampler2,density,delta)\n",
    "ulaSampler1 = ULASampler(gradLog,startSampler1,delta)\n",
    "ulaSampler2 = ULASampler(gradLog,startSampler2,delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\"MALA1\": {\"sampler\":malaSampler1},\n",
    "               \"MALA2\": {\"sampler\":malaSampler2},\n",
    "               \"ULA1\": {\"sampler\":ulaSampler1},\n",
    "               \"ULA2\": {\"sampler\":ulaSampler2}}\n",
    "expResults = {expId: exp[\"sampler\"].sample(10000,burnIn=1, parallelChains=False) for expId,exp in experiments.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "ax.grid()\n",
    "ax.set_title(\"Значения цепей\")\n",
    "\n",
    "expKeys = list(experiments.keys())\n",
    "for key in expKeys:\n",
    "    ax.scatter(np.arange(expResults[key].shape[0])[::20],expResults[key].squeeze()[::20],alpha=0.7)\n",
    "\n",
    "ax.legend(expKeys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MALA мало смысла запускать с плохого старта из региона с низкой плотностью, потому что мы часто будем отклонять семпл. Поэтому если алгоритм не сходится, всегда можно начать с ULA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Плотность посложнее (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим диффузию в $\\mathbb{R}^2$\n",
    "\n",
    "$$\n",
    "dX_t = b(X_t)dt + \\sqrt{2} dW_t, \\quad b(x,y) = -0.5[x/250 + 4x(y+2x^2-10), ~ 2(y+2x^2-10) ]^T\n",
    "$$\n",
    "\n",
    "Вычислите стационарную плотность этой диффузии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАШЕ РЕШЕНИЕ ЗДЕСЬ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5 баллов) Семплирование\n",
    "\n",
    "Постройте семплы спомощью алгоритмов MALA и ULA из начального распределения, которое вам кажется удобнее, обоснуйте свой выбор.\n",
    "\n",
    "Запустите параллельно $1000$ цепей для каждого алгоритма и нарисуйте на плоскости их положения в разные моменты времени $t=1,1000,10000,100000$(вам поможет реинициализация с помощью ConstExactSampler). Когда примерно цепь доходит до эргодического состояния? Попробуйте разные размеры шага $\\texttt{delta}=0.01,0.1,0.001$, как изменятся результаты работы алгоритма? Для стартового разогрева можно использовать ULA, если в MALA много отвержений, а потом перейти на MALA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass t because of solver\n",
    "\n",
    "def gradLog(t,x):\n",
    "    #print(x.shape)\n",
    "    #return ??? YOUR CODE\n",
    "    pass\n",
    "def logDensity(x):\n",
    "    #return ??\n",
    "    #YOUR CODE\n",
    "    pass\n",
    "\n",
    "startSampler = GaussianSampler(np.zeros([2])+4,np.array([[1,0],[0,1]]))\n",
    "delta = 0.1\n",
    "ulaSampler00 = ULASampler(gradLog,startSampler,delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstExactSampler(Sampler):\n",
    "    \n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "    def sample(self,N):\n",
    "        return self.x\n",
    "    \n",
    "#dummy thing for checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(7,7))\n",
    "\n",
    "ax.grid()\n",
    "ax.set_title(\"Значения цепей\")\n",
    "\n",
    "#example\n",
    "#ax.scatter(samples00[:,0],samples00[:,1],alpha=0.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАШ КОД И КОММЕНТАРИИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
